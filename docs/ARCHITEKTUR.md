# ğŸ—ï¸ Kamera-Auto-Trigger Architektur

## SystemÃ¼bersicht

Das Kamera-Auto-Trigger System ist eine verteilte Anwendung zur automatischen Vogel-Erkennung und -Aufnahme. Es besteht aus zwei Hauptkomponenten:

- **PC (Lokales System)**: KI-gestÃ¼tzte Echtzeit-Analyse des Preview-Streams
- **Raspberry Pi 5 (Remote)**: HochauflÃ¶sende Video- und Audio-Aufnahme

---

## ğŸ”„ Kommunikationsfluss

### Gesamtarchitektur

```mermaid
graph TB
    subgraph PC["PC (Lokales System)"]
        A["start-vogel-beobachtung.sh<br/>ğŸš€ Wrapper Script"]
        B["ai-had-kamera-auto-trigger.py<br/>ğŸ§  Haupt-Controller"]
        C["stream_processor.py<br/>ğŸ¤– YOLOv8 KI-Modul"]
        D["config.py<br/>âš™ï¸ Konfiguration"]
    end
    
    subgraph RaspPi["Raspberry Pi 5 (Remote)"]
        E["libcamera-vid<br/>ğŸ“¹ Preview Stream"]
        F["Aufnahme-Skript<br/>ğŸ¬ HD Recording"]
        G["USB-Mikrofon<br/>ğŸ¤ Audio Input"]
    end
    
    A -->|Parameter| B
    B -->|Konfiguration| D
    B -->|"RTSP Verbindung"| E
    E -->|"Stream 640x480@5fps"| C
    C -->|"Vogel erkannt?"| B
    B -->|"SSH Befehl"| F
    F -->|Aufnahme| G
    F -->|"Video Output"| H["ğŸ“ Videos/"]
    F -->|"Audio Output"| H

    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#ffe1f5
    style E fill:#e1ffe1
    style F fill:#ffe1e1
    style G fill:#f5e1ff
```

---

## ğŸ“Š Detaillierter Ablauf

### 1ï¸âƒ£ Systemstart

```mermaid
sequenceDiagram
    participant User
    participant Wrapper as start-vogel-beobachtung.sh
    participant Controller as ai-had-kamera-auto-trigger.py
    participant RaspPi as Raspberry Pi 5

    User->>Wrapper: ./start-vogel-beobachtung.sh [--with-ai | --slowmo]
    
    Note over Wrapper: System-Checks
    Wrapper->>Wrapper: âœ“ Python venv aktivieren
    Wrapper->>Wrapper: âœ“ AbhÃ¤ngigkeiten prÃ¼fen
    Wrapper->>Wrapper: âœ“ SSH-Agent starten
    Wrapper->>Wrapper: âœ“ Netzwerk prÃ¼fen
    
    Wrapper->>Controller: python ai-had-kamera-auto-trigger.py<br/>--preview-fps 3<br/>--preview-width 320<br/>--preview-height 240
    
    Note over Controller: Initialisierung
    Controller->>Controller: CPU-Optimierung setzen<br/>(OMP_NUM_THREADS=2)
    Controller->>RaspPi: SSH Verbindung aufbauen
    RaspPi-->>Controller: âœ“ Verbunden
    
    Controller->>RaspPi: libcamera-vid starten<br/>(Preview: 640x480@5fps)
    RaspPi-->>Controller: RTSP Stream: rtsp://raspi:8554/preview
```

---

### 2ï¸âƒ£ Preview Stream & KI-Analyse

```mermaid
sequenceDiagram
    participant RaspPi as Raspberry Pi 5
    participant Stream as stream_processor.py
    participant YOLO as YOLOv8 Model
    participant Controller as ai-had-kamera-auto-trigger.py

    loop Kontinuierliche Analyse
        RaspPi->>Stream: RTSP Frame (320x240)<br/>ğŸ“¹ 3-5 FPS
        
        Note over Stream: Frame-Verarbeitung
        Stream->>Stream: Frame dekodieren
        Stream->>Stream: BGR â†’ RGB konvertieren
        
        Stream->>YOLO: model(frame,<br/>  conf=0.5,<br/>  iou=0.45,<br/>  max_det=5,<br/>  imgsz=320)
        
        Note over YOLO: KI-Inferenz<br/>ğŸ§  CPU-optimiert<br/>(320x320 AuflÃ¶sung)
        
        YOLO-->>Stream: Erkennungs-Ergebnisse<br/>(Bounding Boxes, Confidence)
        
        alt Vogel erkannt (conf > 50%)
            Stream-->>Controller: âœ… VOGEL ERKANNT<br/>Klasse: "bird"<br/>Confidence: 85%
            Note over Controller: Trigger Recording
        else Kein Vogel
            Stream-->>Controller: âšª Kein Vogel
            Note over Controller: Weiter Ã¼berwachen
        end
    end
```

---

### 3ï¸âƒ£ Aufnahme-Trigger (3 Modi)

```mermaid
flowchart TD
    Start(["ğŸ¯ Vogel erkannt!"])
    
    Start --> Check{"Welcher Modus?"}
    
    Check -->|--slowmo| Slowmo["ğŸ¬ Zeitlupe-Modus"]
    Check -->|--with-ai| AI["ğŸ¤– KI-Modus"]
    Check -->|Standard| Standard["ğŸ“¹ Standard-Modus"]
    
    Slowmo --> SlowmoScript["ai-had-kamera-remote-param-vogel-<br/>libcamera-zeitlupe.py"]
    AI --> AIScript["ai-had-kamera-remote-param-vogel-<br/>libcamera-single-AI-Modul.py"]
    Standard --> StandardScript["ai-had-kamera-remote-param-vogel-<br/>libcamera-single-AI-Modul.py"]
    
    SlowmoScript --> SlowmoParams["ğŸ“Š Parameter:<br/>- 120 FPS<br/>- 1536x864<br/>- 10 Sek Pre-Record<br/>- 44.1kHz Audio Mono"]
    AIScript --> AIParams["ğŸ“Š Parameter:<br/>- 25 FPS<br/>- 1920x1080<br/>- 5 Sek Pre-Record<br/>- 44.1kHz Audio Mono<br/>- KI-Metadaten"]
    StandardScript --> StandardParams["ğŸ“Š Parameter:<br/>- 25 FPS<br/>- 1920x1080<br/>- 5 Sek Pre-Record<br/>- 44.1kHz Audio Mono"]
    
    SlowmoParams --> Record["ğŸ¬ Aufnahme auf RaspPi"]
    AIParams --> Record
    StandardParams --> Record
    
    Record --> Save["ğŸ’¾ Speichern:<br/>Videos/YYYY-MM-DD_HH-MM-SS.mp4<br/>Videos/YYYY-MM-DD_HH-MM-SS.wav"]
    
    Save --> End(["âœ… Aufnahme beendet"])

    style Start fill:#ffe1e1
    style Check fill:#fff4e1
    style Slowmo fill:#e1f5ff
    style AI fill:#ffe1f5
    style Standard fill:#e1ffe1
    style Record fill:#f5e1ff
    style Save fill:#ffe1e1
```

---

### 4ï¸âƒ£ SSH-Kommunikation im Detail

```mermaid
sequenceDiagram
    participant Controller as ai-had-kamera-auto-trigger.py
    participant SSH as SSH Client<br/>(Paramiko)
    participant RaspPi as Raspberry Pi 5
    participant Script as Aufnahme-Skript
    participant Camera as libcamera-vid
    participant Mic as USB-Mikrofon

    Note over Controller: ğŸ¯ Vogel erkannt!
    
    Controller->>SSH: SSH Session Ã¶ffnen
    SSH->>RaspPi: Verbindung Ã¼ber Port 22
    RaspPi-->>SSH: âœ“ Authentifiziert
    
    SSH->>RaspPi: python3 /home/pi/Scripts/...-zeitlupe.py<br/>--duration 20<br/>--output Videos/2025-10-03_14-30-45.mp4
    
    RaspPi->>Script: Skript starten
    
    Note over Script: Audio-GerÃ¤t erkennen
    Script->>Mic: USB-Audio-GerÃ¤t suchen
    Mic-->>Script: hw:2,0 (USB PnP Sound Device)
    
    par Parallele Aufnahme
        Script->>Camera: libcamera-vid starten<br/>--width 1536<br/>--height 864<br/>--framerate 120<br/>--codec h264
        Camera-->>Script: Video Stream
        
        and
        
        Script->>Mic: arecord starten<br/>-D hw:2,0<br/>-f S16_LE<br/>-r 44100<br/>-c 1
        Mic-->>Script: Audio Stream
    end
    
    Note over Script: â±ï¸ 20 Sekunden Aufnahme
    
    Script->>Script: Video + Audio muxen<br/>(ffmpeg)
    
    Script-->>RaspPi: âœ… Aufnahme gespeichert<br/>Videos/2025-10-03_14-30-45.mp4<br/>Videos/2025-10-03_14-30-45.wav
    
    RaspPi-->>SSH: Exit Code: 0
    SSH-->>Controller: âœ“ Aufnahme erfolgreich
    
    Note over Controller: Cooldown 5 Sek<br/>Weiter Ã¼berwachen...
```

---

## âš™ï¸ CPU-Optimierung Details

```mermaid
graph LR
    subgraph Optimization["ğŸ¯ CPU-Optimierung"]
        A["Original<br/>107% CPU"] -->|"Thread-Limit"| B["82.5% CPU<br/>OMP/BLAS=2"]
        B -->|"FPS 5â†’3"| C["82.5% CPU<br/>Weniger Frames"]
        C -->|"Preview 320x240"| D["92% CPU<br/>âš ï¸ Anstieg!"]
        D -->|"imgsz=320"| E["40% CPU<br/>âœ… -63%"]
    end
    
    style A fill:#ff9999
    style B fill:#ffcc99
    style C fill:#ffff99
    style D fill:#ffcc99
    style E fill:#99ff99

    Note1["ğŸ“Š Optimierungs-Strategien"]
    Note1 -.->|1| F["Thread-BeschrÃ¤nkung<br/>OMP_NUM_THREADS=2"]
    Note1 -.->|2| G["Frame-Rate reduzieren<br/>5fps â†’ 3fps"]
    Note1 -.->|3| H["Preview-AuflÃ¶sung<br/>640x480 â†’ 320x240"]
    Note1 -.->|4| I["YOLO Inferenz-GrÃ¶ÃŸe<br/>imgsz=320"]
```

**ErklÃ¤rung:**
1. **Thread-Limit**: Begrenzt parallele CPU-Threads fÃ¼r NumPy/OpenBLAS
2. **FPS-Reduktion**: Weniger Frames pro Sekunde â†’ weniger Analysen
3. **Preview-AuflÃ¶sung**: Kleinere Stream-AuflÃ¶sung (nicht die Aufnahme!)
4. **YOLO imgsz=320**: ğŸ¯ **Durchbruch!** YOLO rechnet intern mit 320x320 statt Vollbild

---

## ğŸ”Œ DatenflÃ¼sse

### Video-Pipeline

```mermaid
flowchart LR
    subgraph RaspPi["ğŸ“¹ Raspberry Pi 5"]
        A1["Camera<br/>IMX708"] -->|RAW| A2["libcamera-vid"]
        A2 -->|H.264| A3["RTSP Server<br/>Port 8554"]
    end
    
    subgraph Network["ğŸŒ Netzwerk"]
        A3 -->|"RTSP Stream<br/>320x240@3fps"| B1["rtsp://raspi:8554/preview"]
    end
    
    subgraph PC["ğŸ’» PC"]
        B1 -->|OpenCV| B2["VideoCapture"]
        B2 -->|Frame| B3["YOLOv8"]
        B3 -->|Ergebnis| B4["Controller"]
    end
    
    B4 -->|"SSH Trigger"| C1["HD Aufnahme"]
    
    subgraph Recording["ğŸ¬ Aufnahme"]
        C1 -->|"1920x1080@25fps"| C2["MP4 Video"]
        C1 -->|"120fps @ Zeitlupe"| C3["MP4 Zeitlupe"]
    end

    style A2 fill:#e1ffe1
    style A3 fill:#e1f5ff
    style B3 fill:#ffe1f5
    style C2 fill:#ffe1e1
    style C3 fill:#fff4e1
```

### Audio-Pipeline

```mermaid
flowchart LR
    subgraph RaspPi["ğŸ¤ Raspberry Pi 5"]
        A1["USB-Mikrofon<br/>hw:2,0"] -->|PCM| A2["arecord"]
        A2 -->|"S16_LE<br/>44.1kHz Mono"| A3["WAV Datei"]
    end
    
    subgraph Optional["ğŸ”§ Optional"]
        A3 -.->|ffmpeg| B1["In MP4 muxen"]
    end
    
    A3 --> C1["ğŸ’¾ Videos/<br/>YYYY-MM-DD_HH-MM-SS.wav"]
    B1 -.-> C2["ğŸ’¾ Videos/<br/>YYYY-MM-DD_HH-MM-SS.mp4<br/>mit Audio-Spur"]

    style A1 fill:#f5e1ff
    style A2 fill:#e1f5ff
    style A3 fill:#ffe1e1
```

### Audio-Pipeline

```mermaid
flowchart LR
    subgraph RaspPi["ğŸ¤ Raspberry Pi 5"]
        A1[USB-Mikrofon<br/>hw:2,0] -->|PCM| A2[arecord]
        A2 -->|S16_LE<br/>44.1kHz Mono| A3[WAV Datei]
    end
    
    subgraph Optional["ğŸ”§ Optional"]
        A3 -.->|ffmpeg| B1[In MP4 muxen]
    end
    
    A3 --> C1[ğŸ’¾ Videos/<br/>YYYY-MM-DD_HH-MM-SS.wav]
    B1 -.-> C2[ğŸ’¾ Videos/<br/>YYYY-MM-DD_HH-MM-SS.mp4<br/>mit Audio-Spur]

    style A1 fill:#f5e1ff
    style A2 fill:#e1f5ff
    style A3 fill:#ffe1e1
    style C1 fill:#99ff99
```

---

## ğŸ›ï¸ Konfigurations-Hierarchie

```mermaid
flowchart TD
    User["ğŸ‘¤ Benutzer"]
    
    User -->|"Modus wÃ¤hlen"| Wrapper["start-vogel-beobachtung.sh"]
    
    Wrapper -->|"Default Parameter"| Config{"Konfigurations-<br/>Ebenen"}
    
    Config -->|"Ebene 1"| HardCoded["Hardcodierte Defaults<br/>in Python-Skript"]
    Config -->|"Ebene 2"| WrapperParams["Wrapper-Parameter<br/>--preview-fps 3 etc."]
    Config -->|"Ebene 3"| UserArgs["Benutzer-Argumente<br/>CLI-Ãœbersteuerung"]
    
    HardCoded --> Merge["âš™ï¸ Parameter Merge"]
    WrapperParams --> Merge
    UserArgs --> Merge
    
    Merge --> Final["Finale Konfiguration"]
    
    Final --> Execute["ğŸš€ AusfÃ¼hrung"]
    
    subgraph Examples["ğŸ“‹ Beispiele"]
        E1["Standard: 25fps, 1920x1080"]
        E2["Zeitlupe: 120fps, 1536x864"]
        E3["Preview: 3fps, 320x240"]
    end

    style Config fill:#fff4e1
    style Merge fill:#e1f5ff
    style Final fill:#99ff99
```

**PrioritÃ¤t:** Benutzer-Argumente > Wrapper-Parameter > Defaults

---

## ğŸ§© Modul-AbhÃ¤ngigkeiten

```mermaid
graph TD
    subgraph PyDeps["Python Dependencies"]
        A["ai-had-kamera-auto-trigger.py"]
        B["stream_processor.py"]
        C["config.py"]
    end
    
    subgraph ExtLibs["Externe Libraries"]
        D["OpenCV<br/>cv2"]
        E["Ultralytics<br/>YOLOv8"]
        F["Paramiko<br/>SSH"]
        G["NumPy"]
    end
    
    subgraph Sys["System"]
        H["libcamera-vid<br/>RaspPi"]
        I["RTSP Server<br/>MediaMTX"]
        J["USB Audio<br/>ALSA"]
    end
    
    A --> B
    A --> C
    A --> F
    
    B --> D
    B --> E
    B --> G
    
    A -.SSH.-> H
    H -.Stream.-> I
    I -.RTSP.-> D
    
    A -.->|"SSH Trigger"| J

    style A fill:#fff4e1
    style B fill:#ffe1f5
    style E fill:#e1f5ff
    style H fill:#e1ffe1
```

---

## ğŸ“ˆ Performance-Metriken

### CPU-Auslastung nach Optimierung

```mermaid
gantt
    title CPU-Auslastung wÃ¤hrend Auto-Trigger Betrieb
    dateFormat X
    axisFormat %s

    section Baseline
    Python-Prozess (107%) :crit, 0, 107
    
    section Nach Optimierung
    Python-Prozess (40%) :active, 0, 40
    System-Overhead (10%) : 0, 10
    Reserve (50%) : 0, 50
```

### Frame-Processing-Zeiten

| Komponente | Zeit | Anteil |
|------------|------|--------|
| Frame-Empfang (RTSP) | ~10ms | 10% |
| Frame-Dekodierung | ~5ms | 5% |
| YOLOv8 Inferenz (imgsz=320) | ~80ms | 80% |
| Ergebnis-Verarbeitung | ~5ms | 5% |
| **Gesamt** | **~100ms** | **100%** |

**â†’ Theoretische Max-FPS:** 10 FPS  
**â†’ Praktische FPS:** 3 FPS (CPU-schonend)

---

## ğŸ”’ Sicherheit & SSH

```mermaid
flowchart TD
    A[PC] -->|1. SSH-Agent starten| B{SSH-Agent<br/>lÃ¤uft?}
    
    B -->|Nein| C[ssh-agent -s]
    B -->|Ja| D[SSH-Key hinzufÃ¼gen]
    
    C --> D
    D -->|ssh-add| E[Privater SchlÃ¼ssel<br/>~/.ssh/id_ed25519]
    
    E --> F[SSH Verbindung]
    
    F -->|Paramiko| G[Raspberry Pi]
    
    G -->|Authentifizierung| H{Key akzeptiert?}
    
    H -->|Ja| I[âœ… Befehle ausfÃ¼hren]
    H -->|Nein| J[âŒ Verbindung abgelehnt]
    
    I --> K[Python-Skript starten]
    K --> L[libcamera-vid starten]
    K --> M[Aufnahme speichern]

    style E fill:#f5e1ff
    style G fill:#e1ffe1
    style I fill:#99ff99
    style J fill:#ff9999
```

**Sicherheitsfeatures:**
- ğŸ”‘ SSH-Key Authentifizierung (keine PasswÃ¶rter!)
- ğŸ” SSH-Agent fÃ¼r Key-Management
- ğŸš« Nur autorisierte Public Keys auf RaspPi
- ğŸ“ Alle SSH-Befehle geloggt

---

## ğŸ¯ Erkennungs-Workflow

```mermaid
stateDiagram-v2
    [*] --> Initialisierung
    
    Initialisierung --> Monitoring: Stream verfÃ¼gbar
    
    Monitoring --> FrameAnalyse: Frame empfangen
    
    FrameAnalyse --> VogelErkannt: Confidence > 50%
    FrameAnalyse --> KeineErkennung: Confidence â‰¤ 50%
    
    KeineErkennung --> Monitoring: NÃ¤chster Frame
    
    VogelErkannt --> Cooldown_Check: Vogel im Frame
    
    Cooldown_Check --> Aufnahme_Triggern: Cooldown abgelaufen
    Cooldown_Check --> Monitoring: Noch in Cooldown
    
    Aufnahme_Triggern --> SSH_Verbindung
    SSH_Verbindung --> Skript_Ausfuehren
    Skript_Ausfuehren --> Aufnahme_Laeuft
    
    Aufnahme_Laeuft --> Cooldown_Aktiv: Aufnahme beendet
    
    Cooldown_Aktiv --> Monitoring: 5 Sekunden warten
    
    Monitoring --> [*]: Strg+C
    
    note right of VogelErkannt
        Klasse: "bird"
        Confidence: z.B. 0.85
        Bounding Box: [x,y,w,h]
    end note
    
    note right of Cooldown_Aktiv
        Verhindert Mehrfach-
        Aufnahmen des gleichen
        Vogels (5 Sek Pause)
    end note
```

---

## ğŸ“ Datei-Struktur

```
vogel-kamera-linux/
â”œâ”€â”€ kamera-auto-trigger/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ ai-had-kamera-auto-trigger.py  ğŸ§  Haupt-Controller
â”‚   â”‚   â”œâ”€â”€ stream_processor.py            ğŸ¤– YOLOv8 KI-Modul
â”‚   â”‚   â””â”€â”€ config.py                      âš™ï¸ Konfiguration
â”‚   â”œâ”€â”€ start-vogel-beobachtung.sh         ğŸš€ Wrapper-Script
â”‚   â”œâ”€â”€ run-auto-trigger.sh                ğŸ”§ venv Aktivierung
â”‚   â”œâ”€â”€ README.md                          ğŸ“– Dokumentation
â”‚   â””â”€â”€ ARCHITEKTUR.md                     ğŸ—ï¸ Diese Datei
â”‚
â”œâ”€â”€ python-skripte/
â”‚   â”œâ”€â”€ ai-had-kamera-remote-param-vogel-libcamera-single-AI-Modul.py
â”‚   â”‚                                      ğŸ“¹ Standard/KI Aufnahme
â”‚   â””â”€â”€ ai-had-kamera-remote-param-vogel-libcamera-zeitlupe.py
â”‚                                          ğŸ¬ Zeitlupen-Aufnahme
â”‚
â”œâ”€â”€ git-automation/
â”‚   â”œâ”€â”€ git_automation.py                  ğŸ”„ Git Automatisierung
â”‚   â””â”€â”€ GIT_AUTOMATION_README.md
â”‚
â””â”€â”€ Videos/                                ğŸ’¾ Aufnahme-Verzeichnis
    â”œâ”€â”€ 2025-10-03_14-30-45.mp4
    â”œâ”€â”€ 2025-10-03_14-30-45.wav
    â””â”€â”€ ...
```

---

## ğŸš€ Startup-Sequenz im Detail

```mermaid
sequenceDiagram
    autonumber
    
    participant User
    participant Wrapper as Wrapper Script
    participant AutoTrigger as Auto-Trigger
    participant StreamProc as Stream Processor
    participant RaspPi
    participant YOLO as YOLOv8
    
    User->>Wrapper: ./start-vogel-beobachtung.sh --with-ai
    
    Note over Wrapper: ğŸ” System-Checks
    Wrapper->>Wrapper: Python venv prÃ¼fen
    Wrapper->>Wrapper: SSH-Agent prÃ¼fen/starten
    Wrapper->>Wrapper: RaspPi Netzwerk-Ping
    
    Wrapper->>AutoTrigger: Python-Skript starten
    
    Note over AutoTrigger: âš™ï¸ CPU-Optimierung
    AutoTrigger->>AutoTrigger: OMP_NUM_THREADS=2 setzen
    AutoTrigger->>AutoTrigger: OPENBLAS_NUM_THREADS=2
    AutoTrigger->>AutoTrigger: MKL_NUM_THREADS=2
    
    Note over AutoTrigger: ğŸ”Œ Verbindungen
    AutoTrigger->>RaspPi: SSH Verbindung herstellen
    RaspPi-->>AutoTrigger: âœ“ Verbunden
    
    AutoTrigger->>RaspPi: libcamera-vid Preview starten
    RaspPi-->>AutoTrigger: RTSP Stream aktiv
    
    AutoTrigger->>StreamProc: Stream Processor initialisieren
    
    StreamProc->>YOLO: YOLOv8 Modell laden
    YOLO-->>StreamProc: âœ“ Modell geladen
    
    StreamProc->>RaspPi: RTSP Verbindung Ã¶ffnen
    RaspPi-->>StreamProc: âœ“ Stream empfangen
    
    Note over AutoTrigger: âœ… System bereit
    
    loop Kontinuierliche Ãœberwachung
        StreamProc->>RaspPi: Frame anfordern
        RaspPi-->>StreamProc: Frame (320x240)
        StreamProc->>YOLO: Inferenz (imgsz=320)
        YOLO-->>StreamProc: Erkennungen
        StreamProc-->>AutoTrigger: Ergebnis
        
        alt Vogel erkannt
            AutoTrigger->>RaspPi: HD-Aufnahme triggern
            RaspPi-->>AutoTrigger: âœ“ Aufnahme gespeichert
            AutoTrigger->>AutoTrigger: 5 Sek Cooldown
        end
    end
```

---

## ğŸ”§ Fehlerbehandlung

```mermaid
flowchart TD
    Start(["Fehler aufgetreten"])
    
    Start --> Type{"Fehler-Typ?"}
    
    Type -->|Netzwerk| N1["Ping RaspPi"]
    Type -->|SSH| S1["SSH-Agent prÃ¼fen"]
    Type -->|Stream| St1["RTSP Server prÃ¼fen"]
    Type -->|KI| K1["YOLO Modell prÃ¼fen"]
    
    N1 --> N2{"Erreichbar?"}
    N2 -->|Ja| N3["Firewall prÃ¼fen"]
    N2 -->|Nein| N4["âŒ RaspPi offline"]
    
    S1 --> S2{"Agent lÃ¤uft?"}
    S2 -->|Ja| S3["SSH-Key hinzufÃ¼gen"]
    S2 -->|Nein| S4["ssh-agent starten"]
    
    St1 --> St2{"Stream lÃ¤uft?"}
    St2 -->|Ja| St3["Neu verbinden"]
    St2 -->|Nein| St4["libcamera-vid neu starten"]
    
    K1 --> K2{"Modell vorhanden?"}
    K2 -->|Ja| K3["Ultralytics neu installieren"]
    K2 -->|Nein| K4["âŒ Modell fehlt"]
    
    N3 --> Retry["â™»ï¸ Verbindung wiederholen"]
    S3 --> Retry
    S4 --> Retry
    St3 --> Retry
    St4 --> Retry
    K3 --> Retry
    
    Retry --> Success{Erfolgreich?}
    Success -->|Ja| End([âœ… Weiter betrieben])
    Success -->|Nein| Error([âŒ Abbruch])
    
    style Start fill:#ffe1e1
    style Error fill:#ff9999
    style End fill:#99ff99
```

**Automatische Recovery:**
- **Netzwerk-Timeout**: Auto-Reconnect nach 5 Sekunden
- **Stream-Unterbrechung**: Automatischer Stream-Neustart
- **SSH-Fehler**: SSH-Agent Neuinitialisierung
- **Frame-Drop**: Frame Ã¼berspringen, weiter Ã¼berwachen

---

## ğŸ“Š Monitoring & Logging

```mermaid
graph TB
    subgraph LogSys["Logging-System"]
        A["Auto-Trigger"] -->|stdout| B["Konsole"]
        A -->|stderr| C["Fehler-Log"]
        A -->|Statistiken| D["Performance-Metriken"]
    end
    
    subgraph Outputs["Ausgaben"]
        B --> B1["ğŸš€ System-Start"]
        B --> B2["ğŸ¯ Erkennungen"]
        B --> B3["ğŸ“¹ Aufnahmen"]
        B --> B4["âš™ï¸ Status-Updates"]
        
        C --> C1["âŒ SSH-Fehler"]
        C --> C2["âš ï¸ Stream-Probleme"]
        C --> C3["ğŸ› Python-Exceptions"]
        
        D --> D1["ğŸ“ˆ CPU-Auslastung"]
        D --> D2["ğŸ–¼ï¸ FPS Counter"]
        D --> D3["ğŸ¯ Erkennungs-Rate"]
        D --> D4["ğŸ’¾ Speicher-Nutzung"]
    end

    style A fill:#fff4e1
    style B fill:#e1f5ff
    style C fill:#ffe1e1
    style D fill:#e1ffe1
```

**Log-Beispiele:**

```
ğŸš€ Vogel-Beobachtung mit KI gestartet
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Aufnahme-Modus: ğŸ¤– Mit KI + Audio (yolov8n.pt)
Preview: 320x240 @ 3 FPS
Recording: 1920x1080 @ 25 FPS + 44.1kHz Mono
CPU-Optimierung: OMP_NUM_THREADS=2
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ“ SSH Verbindung hergestellt
âœ“ RTSP Stream aktiv: rtsp://raspi:8554/preview
âœ“ YOLOv8 Modell geladen

[14:30:45] ğŸ¯ VOGEL ERKANNT! Confidence: 85%
[14:30:45] ğŸ“¹ Aufnahme gestartet: Videos/2025-10-03_14-30-45.mp4
[14:31:05] âœ… Aufnahme beendet (20 Sekunden)
[14:31:05] â¸ï¸ Cooldown: 5 Sekunden

Performance: CPU 40% | FPS 3.2 | RAM 180MB
```

---

## ğŸ“ Zusammenfassung

### Haupt-Komponenten

| Komponente | Funktion | Technologie |
|------------|----------|-------------|
| **Preview Stream** | Niedrig-auflÃ¶sende Echtzeit-Ãœberwachung | RTSP, libcamera-vid |
| **KI-Modul** | Vogel-Erkennung in Echtzeit | YOLOv8, OpenCV |
| **Controller** | Orchestrierung & Trigger-Logik | Python, Paramiko |
| **Recording** | HD-Aufnahme mit Audio | libcamera-vid, arecord |
| **SSH-Layer** | Sichere Remote-Kommunikation | SSH, SSH-Agent |

### Datenfluss-Zusammenfassung

1. **RaspPi** sendet Preview-Stream (320x240, 3fps) via RTSP
2. **PC** analysiert Stream mit YOLOv8 (imgsz=320 fÃ¼r CPU-Effizienz)
3. Bei Vogel-Erkennung: **SSH-Trigger** an RaspPi
4. **RaspPi** startet HD-Aufnahme (1920x1080, 25fps oder 120fps)
5. **Audio** wird parallel aufgenommen (44.1kHz Mono)
6. **Speicherung** erfolgt lokal auf RaspPi als MP4 + WAV

### Performance-Optimierungen

```
ğŸ”§ Thread-Limiting â†’ ğŸ”§ FPS-Reduktion â†’ ğŸ”§ AuflÃ¶sung â†’ ğŸ¯ YOLO imgsz=320
   (OMP=2)              (3 FPS)          (320x240)       (DURCHBRUCH!)
   
   107% â†’ 82% â†’ 82% â†’ 40% CPU âœ…
```

### Modi-Ãœbersicht

| Modus | FPS | AuflÃ¶sung | Audio | Verwendung |
|-------|-----|-----------|-------|------------|
| **Standard** | 25 | 1920x1080 | âœ… 44.1kHz | Normale Aufnahmen |
| **Mit KI** | 25 | 1920x1080 | âœ… 44.1kHz | Mit KI-Metadaten |
| **Zeitlupe** | 120 | 1536x864 | âœ… 44.1kHz | Slow-Motion |

---

## ğŸ”— Referenzen

- [YOLOv8 Dokumentation](https://docs.ultralytics.com/)
- [libcamera Dokumentation](https://libcamera.org/)
- [OpenCV Dokumentation](https://docs.opencv.org/)
- [Paramiko SSH Library](https://www.paramiko.org/)
- [Raspberry Pi Camera Dokumentation](https://www.raspberrypi.com/documentation/computers/camera_software.html)

---

**Version:** 1.2.0  
**Letzte Aktualisierung:** 3. Oktober 2025  
**Status:** âœ… Produktiv im Einsatz
